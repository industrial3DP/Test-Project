# Hello World Tkinter Tutorial

This small project demonstrates a minimal Tkinter GUI in Python. It's
intended as a tutorial/example you can read and run to learn the basics.

Files
- `python_test_0.1.py` — A short, well-commented Tkinter app: a label and a
- `python_test_0.1.py` — A short, well-commented Tkinter app: a label and a
  button. Clicking the button updates the label and shows an info dialog.
  The project has been extended into a joke app where the button becomes
  increasingly evasive: it moves, changes size, jiggles, and can evade the
  cursor after repeated clicks. A click counter tracks how many times the
  user has clicked the button. The app can also generate context-aware
  snarky replies using a local Ollama model.

Quick start (Windows PowerShell)
```powershell
python "...\VS Workspaces\Test Project\python_test_0.1.py"
```

What you'll learn
- How to import and use `tkinter` and `messagebox`.
- Basic widget creation: `Label` and `Button`.
- Wiring a callback (`command=`) to react to user input.
- The meaning of the Tk event loop (`mainloop()`).

Notes and troubleshooting
- Tkinter is included with the standard CPython installer on Windows. If
  `import tkinter` fails, install Python from the official installer and
  ensure the "tcl/tk and IDLE" option is selected.
- This example uses a module-level variable for simplicity. In production
  code prefer a class-based structure for better encapsulation.

Ollama (local LLM) support
- This project can use a locally-installed Ollama model to generate dynamic
  snarky replies instead of static canned messages. Benefits: no network
  calls to remote APIs, more creative responses, and full local control.

Setup (Windows PowerShell)
1. Install Ollama and a model following Ollama's docs: https://ollama.ai
2. Verify `ollama` is in your PATH (PowerShell):
```powershell
ollama --help
```
3. (Optional) Choose or install a model. Set the model name in the environment
   variable `OLLAMA_MODEL` if you want a model other than the default used by
   the app. Example (PowerShell):
```powershell
$env:OLLAMA_MODEL = 'your_model_name'
```

How the app uses Ollama
- The app calls the Ollama CLI (`ollama generate <model> "prompt"`) on a
  background thread so the GUI doesn't freeze. If the CLI or model is not
  available or the call times out, the app falls back to canned snarky replies.
- The prompt is context-aware: it includes the click count and difficulty to
  produce tailored responses.

UI notes
- There's an LLM indicator in the top-right that shows whether LLM replies
  are enabled (green = On, red = Off).
- The LLM toggle is intentionally hidden: right-click the main label ("Don't
  Click the Button!") to open a small secret menu with "Toggle LLM (secret)".
  You can also press Ctrl+L to toggle LLM on/off. If you prefer a visible
  control, right-click and choose "Show LLM Button" to reveal a toggle button.

Security and privacy
- All model generation happens locally via your Ollama installation. No
  content is sent to remote servers by this app unless you use a remote
  Ollama service intentionally.


New behaviours (joke app)
- The app counts button clicks and displays the count in the main label.
- Each click increases the "difficulty" and triggers an effect:
  - small random moves, shrinking/growing, jiggle animation, and cursor-evade.
- The button remains clickable by design; the effects are intentionally
  mild so you can still catch it with persistence.

If you want to explore further
- Convert the module-level state into an Application class.
- Add a UI control to toggle evasive behaviour on/off for experimentation.

Exercises (next steps for practice)
- Add a second button that restores the original label text.
- Use `grid()` instead of `pack()` to learn another geometry manager.
- Refactor the app into a class and move the callbacks into instance methods.

License
- This small tutorial is MIT-style: use and adapt freely.
